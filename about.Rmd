---
title: "M√°s all√° de la descripci√≥n: un enfoque inferencial sobre la longevidad"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    code_download: true
    theme: lumen
    number_sections: true
    css: styles.css
bibliography: "biblio.bib"
# csl: apa.csl.txt  
---

# Intervalo de confianza para una sola muestra para la expectativa de vida en 2015

Estimar un intervalo de confianza del 95% para la media de la esperanza de vida en el a√±o 2015 permite complementar la estimaci√≥n puntual con un rango de valores dentro del cual es razonable suponer que se encuentra la verdadera media poblacional, con un determinado nivel de confianza. Este enfoque es especialmente √∫til al trabajar con muestras, ya que incorpora la incertidumbre asociada al proceso de selecci√≥n aleatoria y fortalece la validez de los resultados inferidos.

Sin embargo, antes de aplicar este procedimiento, es necesario verificar que la variable de inter√©s se distribuya de forma aproximadamente normal en la poblaci√≥n, ya que este es uno de los supuestos fundamentales para aplicar t√©cnicas inferenciales cl√°sicas como la construcci√≥n de intervalos de confianza. En caso de no cumplirse dicho supuesto, se puede recurrir al respaldo te√≥rico que ofrece el Teorema Central del L√≠mite, el cual garantiza que, bajo ciertas condiciones, la distribuci√≥n de las medias muestrales se aproxima a una normal, incluso si los datos originales no lo son. Esta propiedad permite justificar el uso de m√©todos basados en la t de Student, asegurando la validez estad√≠stica del intervalo calculado.

## Prueba de normalidad de Shapiro-Wilk

### 1. Formulaci√≥n de hip√≥tesis

Hip√≥tesis nula (ùêª‚ÇÄ):La poblaci√≥n sigue una distribuci√≥n normal.

Hip√≥tesis alternativa (ùêª‚ÇÅ):La poblaci√≥n no sigue una distribuci√≥n normal.

### 2. Formulaci√≥n de hip√≥tesis

Nivel de significaci√≥n: Œ± = 0.05

### 3. Estad√≠stico de prueba

```{r}

datos_2015 <- datos_limpios %>% filter(Year == 2015)

vida_2015 <- datos_2015$`Life expectancy`

normalidad <- shapiro.test(vida_2015)
normalidad 

```

### 4. Comparaci√≥n e interpretaci√≥n

$$
p = 0,0001332 < \alpha = 0.05 
$$
Dado que el p-valor es menor que el nivel de significaci√≥n (Œ± = 0.05), se rechaza la hip√≥tesis nula (H‚ÇÄ).

### 5. Conclusi√≥n 

Como el valor p obtenido en la prueba de normalidad fue de 0.0001332, y este es menor que el nivel de significancia establecido (\( \alpha = 0.05 \)), se rechaza la hip√≥tesis nula. Esto indica que la variable esperanza de vida en 2015 no se distribuye normalmente en la poblaci√≥n. Sin embargo, dado que la muestra utilizada es suficientemente grande (\( n = 50 \)), se puede aplicar el Teorema Central del L√≠mite, el cual garantiza que la distribuci√≥n de la media muestral tiende a ser normal bajo ciertas condiciones. Por ello, se justifica el uso de un intervalo de confianza para la media utilizando la t de Student.



## Intervalo de confianza del 95% de una muestra 

En este an√°lisis se trabajar√° con la variable cuantitativa Life expectancy correspondiente al a√±o 2015. A partir de la poblaci√≥n total de pa√≠ses registrados para ese a√±o, se extrajo una muestra aleatoria de 50 pa√≠ses con el objetivo de estimar, con un nivel de confianza del 95%, el valor medio poblacional de la esperanza de vida. Aunque ser√≠a posible calcular la desviaci√≥n est√°ndar de la poblaci√≥n completa, se opta por mantener un enfoque estrictamente inferencial, tratando los datos como una muestra. Por esta raz√≥n, se utiliza la desviaci√≥n est√°ndar muestral como estimador y se recurre a la distribuci√≥n t de Student para construir el intervalo de confianza.

```{r}
# Extraer la variable de inter√©s desde la muestra
vida_muestra <- muestra_final$`Life expectancy`

# Calcular tama√±o, media, desviaci√≥n y error est√°ndar
n <- length(vida_muestra)
media <- mean(vida_muestra)
desv <- sd(vida_muestra)
error <- desv / sqrt(n)

# Valor t cr√≠tico (nivel de confianza 95%)
t <- qt(0.975, df = n - 1)

# Calcular intervalo
li <- media - t * error
ls <- media + t * error

# Mostrar resultados de forma sencilla
cat("Intervalo de confianza del 95% para la media:\n")
cat(sprintf("[%.2f, %.2f]\n", li, ls))
cat(sprintf("Media: %.2f | Muestra: %.2f | Error est√°ndar: %.2f | t cr√≠tico: %.3f\n", media, n, error, t))
```

Con base en los resultados obtenidos, se ha estimado un intervalo de confianza del 95% para la media poblacional de la esperanza de vida en el a√±o 2015, que se encuentra entre 69,46 y 74,01 a√±os. Es decir: 69,46 < Œº < 74,01 Esto indica que, con un 95% de confianza, se puede afirmar que la esperanza de vida media global en 2015 se sit√∫a dentro de ese rango. La estimaci√≥n refleja una medida central de longevidad para ese a√±o y ofrece un valor de referencia √∫til para interpretar la situaci√≥n general de salud a nivel mundial en ese periodo.

# Intervalo de confianza para dos muestras con respecto a la variable expectativa de vida

En este apartado se pretende comparar la media de la esperanza de vida entre dos grupos de pa√≠ses clasificados seg√∫n su estatus de desarrollo: Developed y Developing. Esta variable, clave en los estudios de salud p√∫blica y calidad de vida, puede reflejar importantes desigualdades estructurales a nivel global. El objetivo es construir un intervalo de confianza del 95% para la diferencia de medias de la esperanza de vida entre ambos grupos en el a√±o 2015, y con ello estimar en qu√© medida la condici√≥n de desarrollo est√° asociada a una mayor o menor longevidad media. Sin embargo, antes de realizar el an√°lisis, es necesario verificar si se cumplen los supuestos estad√≠sticos que justifican el uso de m√©todos param√©tricos:

1. La normalidad de los datos dentro de cada grupo.

2. La igualdad o desigualdad de varianzas entre las dos poblaciones.

## Prueba de normalidad para paises en desarrollo y desarrollados

### 1. Formulaci√≥n de hip√≥tesis

Hip√≥tesis nula (ùêª‚ÇÄ):La poblaci√≥n sigue una distribuci√≥n normal.

Hip√≥tesis alternativa (ùêª‚ÇÅ) :La poblaci√≥n no sigue una distribuci√≥n normal.

### 2. Formulaci√≥n de hip√≥tesis

Nivel de significaci√≥n: Œ± = 0.05

### 3. Estad√≠stico de prueba

```{r}
datos_2015 <- datos_limpios %>% 
  filter(Year == 2015)

grupo1 <- datos_2015 %>% filter(Status == "Developed") %>% pull(`Life expectancy`)
grupo2 <- datos_2015 %>% filter(Status == "Developing") %>% pull(`Life expectancy`)

shapiro.test(grupo1)  # Developed
shapiro.test(grupo2)  # Developing
```

### 4. Comparaci√≥n e interpretaci√≥n

- Grupo 1 - Developed:
p = 0.05648 > Œ± = 0.05 ‚Üí No se rechaza H‚ÇÄ: se asume normalidad.

- Grupo 2 - Developing:
p = 0.0001726 < Œ± = 0.05 ‚Üí Se rechaza H‚ÇÄ: no se puede asumir normalidad.

### 5. Conclusi√≥n

Tras aplicar la prueba de normalidad de Shapiro-Wilk a los dos grupos definidos por el estatus de desarrollo, se obtuvieron resultados diferenciados.
En el grupo de pa√≠ses desarrollados (Developed), el valor p fue de 0.05648, superior al nivel de significaci√≥n Œ± = 0.05, por lo que no se rechaza la hip√≥tesis nula de normalidad, lo cual indica que los datos de esperanza de vida en este grupo pueden considerarse normalmente distribuidos.

En cambio, para el grupo de pa√≠ses en desarrollo (Developing), el valor p fue de 0.0001726, inferior a Œ± = 0.05, lo que lleva a rechazar la hip√≥tesis nula. Por tanto, se concluye que los datos de esperanza de vida en este grupo no se distribuyen normalmente. Sin embargo, conforme al resultado del chunck posterior, aunque la prueba de Shapiro-Wilk indic√≥ que la variable 'Life expectancy' en el grupo de pa√≠ses en desarrollo (Developing) no sigue una distribuci√≥n normal (p = 0.0001726 < 0.05),el tama√±o muestral de este grupo es de 39 observaciones, por lo que con base al Teorema Central del L√≠mite, se considera razonable asumir que la distribuci√≥n de la media muestral se aproxima a una normal.  

```{r}
n_developing_muestra <- muestra_final %>%
  filter(Status == "Developing") %>%
  nrow()

cat("Tama√±o de la muestra para pa√≠ses en desarrollo (dentro de la muestra):", n_developing_muestra, "observaciones\n")
```

## Diferencia de varianzas 

```{r}
var.test(grupo1, grupo2)
```

Intervalo de confianza del 95% para el cociente de varianzas:

           0,1286 < œÉ¬≤_Developed / œÉ¬≤_Developing < 0,3903
           
Como el valor 1 no se encuentra dentro del intervalo de confianza, se rechaza la hip√≥tesis nula de igualdad de varianzas.Por tanto, se concluye que las varianzas de ambos grupos son significativamente diferentes,y se debe aplicar el t-test con varianzas desiguales.

## Intervalo de confianza del 95% de dos muestras 

```{r}
# Filtrar datos del a√±o 2015
datos_2015 <- datos_limpios %>%
  filter(Year == 2015)

# Extraer la variable para cada grupo
grupo_desarrollado <- datos_2015 %>%
  filter(Status == "Developed") %>%
  pull(`Life expectancy`)

grupo_desarrollo <- datos_2015 %>%
  filter(Status == "Developing") %>%
  pull(`Life expectancy`)
# Prueba t con varianzas desiguales
resultado_ic <- t.test(grupo_desarrollado, grupo_desarrollo,
                       alternative = "two.sided",
                       var.equal = FALSE,
                       conf.level = 0.95)
# Extraer intervalo y diferencia
lim_inf <- resultado_ic$conf.int[1]
lim_sup <- resultado_ic$conf.int[2]
diferencia_media <- resultado_ic$estimate[1] - resultado_ic$estimate[2]

cat("Intervalo de confianza del 95% para la diferencia de medias:\n")
cat(sprintf("           %.2f < Œº_Developed - Œº_Developing < %.2f\n\n", lim_inf, lim_sup))
cat(sprintf("Diferencia media estimada: %.2f a√±os\n", diferencia_media))
```

El an√°lisis del intervalo de confianza del 95% para la diferencia de medias entre los pa√≠ses desarrollados y en desarrollo muestra una diferencia significativa en la esperanza de vida. El intervalo calculado entre 9,31 y 12,73 a√±os indica que, con un alto nivel de certeza, los pa√≠ses desarrollados presentan una esperanza de vida considerablemente superior respecto a los pa√≠ses en desarrollo.

En concreto, la diferencia media estimada es de 11,02 a√±os, lo que significa que, en promedio, las personas que viven en pa√≠ses desarrollados pueden esperar vivir m√°s de una d√©cada m√°s que quienes residen en pa√≠ses en desarrollo. Este dato no solo es estad√≠sticamente significativo, sino que tambi√©n tiene una gran relevancia pr√°ctica y social, ya que refleja profundas diferencias estructurales en t√©rminos de calidad de vida, acceso a recursos sanitarios, condiciones ambientales y estabilidad econ√≥mica.

El hecho de que el intervalo no contenga el valor cero confirma que la diferencia no es producto del azar. Por tanto, podemos afirmar con evidencia estad√≠stica que el estatus de desarrollo est√° claramente asociado a una mayor longevidad. En los pa√≠ses desarrollados, la esperanza de vida tiende a ser m√°s alta gracias a sistemas de salud m√°s robustos, mejores condiciones de vida y mayor prevenci√≥n de enfermedades, entre otros factores. Por el contrario, en muchos pa√≠ses en desarrollo persisten desaf√≠os estructurales que limitan el acceso a servicios esenciales, lo que se traduce en una menor esperanza de vida.

# Recomendaciones ante no normalidad de la poblaci√≥n 

Cuando los datos no cumplen el supuesto de normalidad, como ocurri√≥ en algunos casos del presente an√°lisis, es fundamental considerar alternativas metodol√≥gicas que se adapten mejor a la estructura real de la informaci√≥n. Una de las primeras opciones es el uso de pruebas no param√©tricas, que permiten realizar comparaciones o contrastes sin asumir que los datos siguen una distribuci√≥n normal. Estas pruebas son especialmente √∫tiles con muestras peque√±as o cuando existen valores at√≠picos. Por ejemplo, la prueba de Mann‚ÄìWhitney U permite comparar dos grupos independientes sin necesidad de suponer normalidad ni igualdad de varianzas, siendo apropiada para variables como la esperanza de vida seg√∫n el nivel de desarrollo. La prueba de Kolmogorov‚ÄìSmirnov, por su parte, permite comparar dos distribuciones completas o evaluar el ajuste a una distribuci√≥n te√≥rica, mientras que la prueba de Friedman se utiliza en contextos de medidas repetidas o comparaciones entre m√°s de dos condiciones dentro del mismo grupo [@siegel1988; @conover1999].

Otra estrategia es aplicar transformaciones a los datos con el fin de reducir la asimetr√≠a y mejorar el ajuste a la normalidad. La transformaci√≥n logar√≠tmica es especialmente √∫til para variables sesgadas a la derecha, como ingresos o gasto en salud. La ra√≠z cuadrada puede utilizarse con datos de conteo o tasas, ayudando a estabilizar la varianza. Adem√°s, la transformaci√≥n Box‚ÄìCox representa una alternativa m√°s flexible, ya que estima autom√°ticamente el tipo de transformaci√≥n m√°s adecuada para acercar la distribuci√≥n a la normalidad, incluso cuando no es evidente qu√© m√©todo aplicar [@box1964; @osborne2010].

Adem√°s de estas opciones, existen enfoques robustos y emp√≠ricos que no dependen de supuestos fuertes sobre la distribuci√≥n de los datos. Uno de los m√°s destacados es el m√©todo bootstrap, que permite estimar intervalos de confianza generando m√∫ltiples muestras con reemplazo a partir de la muestra original. A partir de esas re-muestras se calcula emp√≠ricamente la distribuci√≥n del estad√≠stico de inter√©s (media, mediana, etc.), sin requerir normalidad. Esto lo convierte en una herramienta vers√°til y poderosa, especialmente en contextos con alta variabilidad o estructura desconocida [@efron1993]. En el caso de modelos de regresi√≥n, tambi√©n pueden emplearse modelos robustos, como la regresi√≥n M o la regresi√≥n cuant√≠lica, los cuales toleran mejor la presencia de valores at√≠picos y errores no normales que la regresi√≥n lineal cl√°sica [@huber2009].

# Modelo de regresi√≥n lineal m√∫ltiple: efecto conjunto de variables seleccionadas

## Identificaci√≥n de la variable dependiente y de las independientes

En el presente modelo de regresi√≥n lineal m√∫ltiple, se busca explicar la esperanza de vida (Life expectancy) durante el 2015, a partir de un conjunto de factores estructurales previamente seleccionados por su relevancia te√≥rica y emp√≠rica. Por tanto, las variables del modelo se clasifican de la siguiente manera:

Variable dependiente (respuesta):

- **Life expectancy:** representa el n√∫mero promedio de a√±os que una persona puede esperar vivir desde su nacimiento, bajo condiciones de mortalidad actuales. Es una variable cuantitativa continua, medida en a√±os. Se considera dependiente porque su valor se ve influido por el comportamiento de las dem√°s variables del modelo.

Variables independientes (predictoras):

- **HIV/AIDS:** porcentaje de la poblaci√≥n adulta infectada con VIH, configurandose como una dimensi√≥n cr√≠tica de salud p√∫blica.

- **Income composition of resources:** √≠ndice entre 0 y 1 que refleja la equidad y composici√≥n de los ingresos disponibles.

- **Adult Mortality:** n√∫mero de muertes por cada mil habitantes entre los 15 y 60 a√±os, representando el riesgo estructural de muerte en edad adulta.

Estas variables se consideran independientes o predictoras porque su funci√≥n en el modelo es explicar o predecir el comportamiento de la variable dependiente. No dependen del valor de la esperanza de vida, sino que act√∫an como insumos cuya combinaci√≥n permite estimar y comprender las variaciones en dicha variable. Adem√°s, fueron seleccionadas por su capacidad para capturar dimensiones clave del desarrollo humano: salud, equidad econ√≥mica y condiciones de vida.

## Ajuste del modelo de regresi√≥n lineal

Una vez identificadas las variables que conforman el modelo, se procede a realizar el ajuste mediante una regresi√≥n lineal m√∫ltiple, el cual estima los coeficientes que cuantifican el efecto de cada variable independiente sobre la esperanza de vida, manteniendo constantes las dem√°s. A partir del modelo ajustado se podr√°n interpretar la magnitud, direcci√≥n y significancia estad√≠stica de cada relaci√≥n. A continuaci√≥n, se muestra el c√≥digo utilizado para realizar dicho ajuste:

```{r}
# Modelo de regresi√≥n lineal m√∫ltiple
modelo <- lm(`Life expectancy` ~ `HIV/AIDS` + 
               `Income composition of resources` + `Adult Mortality` , 
             data = muestra_final)

summary(modelo)
```

A partir de la salida del modelo de regresi√≥n lineal ajustado en R, obtenemos la siguiente ecuaci√≥n de la recta ajustada:

$$\widehat{\text{Life expectancy}} = 50.95 - 1.56 \times \text{HIV/AIDS} + 34.78 \times \text{Income composition of resources} - 0.015 \times \text{Adult Mortality}$$

En donde:

- $\beta_0$ Intercepto (50.95):
Representa la esperanza de vida estimada cuando todas las variables independientes son iguales a cero. Aunque este escenario es hipot√©tico (por ejemplo, 0 en prevalencia de VIH, sin ingresos y sin mortalidad adulta), el intercepto es esencial para ajustar el modelo y sirve como base en la predicci√≥n de la esperanza de vida.

- $\beta_1$ HIV/AIDS (-1.56):
Por cada punto porcentual adicional en la prevalencia de VIH/SIDA en la poblaci√≥n adulta (de 15 a 49 a√±os), se estima que la esperanza de vida disminuye en promedio 1.56 a√±os, manteniendo constantes las dem√°s variables. Este resultado refleja c√≥mo la presencia de enfermedades infecciosas impacta negativamente la longevidad de una poblaci√≥n.

- $\beta_2$ Income composition of resources (34.79):
Por cada unidad adicional en el √≠ndice de composici√≥n del ingreso (que va de 0 a 1), la esperanza de vida aumenta en promedio 34.79 a√±os. Este coeficiente indica que un mejor acceso a recursos econ√≥micos est√° estrechamente relacionado con mejores condiciones de salud y, por tanto, con una mayor esperanza de vida.

- $\beta_3$ Adult Mortality (-0.0152):
Por cada muerte adicional por cada mil adultos entre 15 y 60 a√±os, la esperanza de vida se reduce en promedio 0.015 a√±os. Aunque el valor es peque√±o, su efecto acumulado puede ser significativo en contextos de alta mortalidad adulta, reflejando ambientes con menor bienestar y mayor vulnerabilidad social.

## Coeficiente de determinaci√≥n 

```{r}
# Extraer el R^2 ajustado desde el modelo
r2_ajustado <- summary(modelo)$adj.r.squared

cat("El coeficiente de determinaci√≥n ajustado (R¬≤ ajustado) del modelo es:", round(r2_ajustado, 4))
```

El coeficiente de determinaci√≥n ajustado ($R^2$ ajustado) del modelo es 0.8881, lo que indica que aproximadamente el 88.81% de la variabilidad en la esperanza de vida entre los pa√≠ses analizados puede explicarse de forma conjunta por las variables HIV/AIDS, Income composition of resources y Adult Mortality. Este valor refleja un excelente nivel de ajuste, especialmente considerando que se trabaj√≥ con datos correspondientes exclusivamente al a√±o 2015, y que el modelo fue construido a partir de solo tres variables predictoras seleccionadas de forma deliberada. El 11.19% restante de variabilidad no explicada puede deberse a otros factores no incluidos en el modelo, como el acceso efectivo a servicios de salud, la infraestructura hospitalaria, la calidad ambiental, factores demogr√°ficos, pol√≠ticas sociales o diferencias culturales entre pa√≠ses. Esto sugiere que, si bien el modelo propuesto logra capturar gran parte del comportamiento de la esperanza de vida, a√∫n existen otros determinantes que podr√≠an incorporarse en estudios posteriores para enriquecer la explicaci√≥n del fen√≥meno desde una perspectiva m√°s amplia y multicausal.

## Coeficiente de correlaci√≥n 

```{r}
# Calcular coeficientes de correlaci√≥n de Pearson entre Life expectancy y cada variable explicativa
cor_pearson_hiv <- cor(muestra_final$`Life expectancy`, muestra_final$`HIV/AIDS`, method = "pearson")
cor_pearson_income <- cor(muestra_final$`Life expectancy`, muestra_final$`Income composition of resources`, method = "pearson")
cor_pearson_mortality <- cor(muestra_final$`Life expectancy`, muestra_final$`Adult Mortality`, method = "pearson")

cat("Correlaci√≥n Life expectancy ~ HIV/AIDS:", round(cor_pearson_hiv, 4), "\n")
cat("Correlaci√≥n Life expectancy ~ Income composition of resources:", round(cor_pearson_income, 4), "\n")
cat("Correlaci√≥n Life expectancy ~ Adult Mortality:", round(cor_pearson_mortality, 4), "\n")
```

La correlaci√≥n entre Life expectancy y HIV/AIDS es de -0.6613, lo cual representa una relaci√≥n negativa de magnitud moderada a fuerte. Esto indica que, a medida que aumenta la prevalencia de VIH/SIDA en la poblaci√≥n adulta, la esperanza de vida tiende a disminuir. Aunque no se trata de una asociaci√≥n perfecta, s√≠ muestra una tendencia clara que respalda la inclusi√≥n de esta variable como un factor relevante dentro del modelo explicativo.

En el caso de Income composition of resources, la correlaci√≥n con la esperanza de vida es de 0.8972, lo que representa una asociaci√≥n positiva muy fuerte. Este resultado sugiere que los pa√≠ses con mayor acceso y equidad en los recursos econ√≥micos suelen tener una mayor esperanza de vida. Esto refuerza la idea de que el entorno socioecon√≥mico juega un papel determinante en las condiciones de salud y longevidad de la poblaci√≥n.

Por su parte, Adult Mortality presenta una correlaci√≥n de -0.6792 con la esperanza de vida, lo cual evidencia una relaci√≥n negativa moderadamente fuerte. En contextos donde la mortalidad adulta es m√°s elevada, la esperanza de vida tiende a reducirse notablemente, ya que las muertes en edades productivas afectan directamente el promedio de a√±os de vida esperados al nacer. Este patr√≥n justifica la inclusi√≥n de esta variable en el an√°lisis y aporta informaci√≥n importante sobre el contexto de salud de los pa√≠ses.


## ANOVA y prueba global de significancia

El an√°lisis de varianza (ANOVA) aplicado a modelos de regresi√≥n permite evaluar si el conjunto de variables independientes tiene un efecto significativo sobre la variable dependiente. Esta prueba divide la variabilidad total de los datos en dos componentes: la variabilidad **explicada por el modelo** (regresi√≥n) y la **no explicada** (error o residuos). La prueba F compara estas dos fuentes de variaci√≥n mediante una raz√≥n de medias cuadr√°ticas, si el resultado es significativo, se concluye que el modelo general tiene capacidad explicativa. A continuaci√≥n, se presenta el c√≥digo y los resultados del ANOVA para nuestro modelo de regresi√≥n:

```{r}
anova(modelo)
```

El anterior modelo, se puede compectar mejor de la siguinte forma: 

```{r}
sct <- sum((muestra_final$`Life expectancy` - mean(muestra_final$`Life expectancy`))^2)
scr <- sum((fitted(modelo) - mean(muestra_final$`Life expectancy`))^2)
sce <- sct - scr

df_reg <- length(coef(modelo)) - 1
df_error <- nrow(muestra_final) - df_reg - 1
df_total <- nrow(muestra_final) - 1

mcr <- scr / df_reg
mce <- sce / df_error

f_value <- mcr / mce
p_value <- 1 - pf(f_value, df_reg, df_error)
p_value_formatted <- format(p_value, scientific = TRUE, digits = 10)

resultados_anova <- data.frame(
  Fuente = c("Regresi√≥n (Modelo)", "Error (Residuos)", "Total"),
  SCR = c(scr, sce, sct),
  GL = c(df_reg, df_error, df_total),
  MCR = c(mcr, mce, NA),
  F_value = c(f_value, NA, NA),
  P_valor = c(p_value_formatted, NA, NA)
)

colnames(resultados_anova) <- c(
  "Fuente",
  "Suma de Cuadrados",
  "Grados de Libertad",
  "Media Cuadr√°tica",
  "Valor F",
  "P-Valor"
)

library(kableExtra)

resultados_anova %>%
  kbl(
    format = "html",
    caption = "Resultados del ANOVA para el Modelo de Regresi√≥n",
    align = "c",
    digits = 3
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive", "condensed"),
    full_width = FALSE,
    position = "center"
  ) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE, background = "#DBDBDB") %>%
  row_spec(1:2, background = "white")


```

Como se observa, la suma de cuadrados de la regresi√≥n (SCR = 2800.743) representa una porci√≥n muy significativa de la suma total de cuadrados (SCT = 3129.552), lo que indica que el modelo explica la mayor parte de la variabilidad en la variable dependiente Life expectancy. El valor F obtenido es 130.607, con un p-valor pr√°cticamente igual a cero (0e+00), lo cual indica que el modelo en su conjunto es altamente significativo desde el punto de vista estad√≠stico. En otras palabras, hay evidencia suficiente para afirmar que al menos una de las variables independientes (HIV/AIDS, Income composition of resources o Adult Mortality) tiene un efecto significativo sobre la esperanza de vida. Para sustentar esta conclusi√≥n se plantea la siguiente prueba de hip√≥tesis global basada en el estad√≠stico F:

**1. Formulaci√≥n de la hip√≥tesis nula y alternativa**

- $H_0$: Ninguna de las variables independientes tiene un efecto significativo sobre la variable dependiente (es decir, todos los coeficientes de las variables explicativas son iguales a cero).
  
  $H_0: \beta_1 = \beta_2 = \beta_3 = \beta_4 = 0$

- $H_1$: Al menos uno de los coeficientes de las variables independientes es diferente de cero.

  $H_1:$ Al menos un $\beta_i \neq 0$

**2. Nivel de significancia**

El **nivel de significancia** ($\alpha$) es el umbral que utilizamos para decidir si podemos rechazar la **hip√≥tesis nula**. En este caso, hemos establecido el nivel de significancia en $\alpha = 0.05$, lo que significa que si el **p-valor** calculado es menor que 0.05, rechazamos la hip√≥tesis nula y concluimos que al menos una de las variables independientes tiene un efecto significativo sobre la **esperanza de vida**.

**3. Estad√≠stico de prueba**

Para esto tenemos en cuenta lo siguiente:

```{r}
# Resultado ANOVA a partir del modelo
anova_resultado <- anova(modelo)

# Obtener las sumas de cuadrados
scr <- sum(anova_resultado$`Sum Sq`[1:3])  # Suma de Cuadrados de la Regresi√≥n 
sce <- anova_resultado$`Sum Sq`[4]         # Suma de Cuadrados del Error

# Obtener los grados de libertad
df_reg <- sum(anova_resultado$Df[1:3])
df_error <- anova_resultado$Df[4]

# Calcular valor F
valor_F <- (scr / df_reg) / (sce / df_error)
cat("El valor F calculado es:", round(valor_F, 2), "\n")
```

**4. Criterio de decisi√≥n**

```{r}
# Calcular el valor p asociado al valor F
p_value <- 1 - pf(valor_F, df_reg, df_error)
cat("El valor p asociado al valor F calculado es:", format(p_value, scientific = TRUE), "\n")
```

**5. Interpretaci√≥n y conclusi√≥n **

El valor *p* obtenido a partir del estad√≠stico **F** representa la probabilidad de observar una variabilidad tan alta explicada por el modelo si la hip√≥tesis nula fuera cierta, es decir, si ninguna de las variables predictoras tuviera un efecto significativo sobre la variable dependiente. En este caso, el valor *p* calculado es **0e+00**, lo que en t√©rminos pr√°cticos significa que es **extremadamente cercano a cero** y mucho menor que cualquier nivel de significancia usual, como $\alpha = 0.05$. Este resultado indica que la probabilidad de que el ajuste observado en el modelo haya ocurrido por azar es pr√°cticamente nula. Por lo tanto, **se rechaza la hip√≥tesis nula** y se concluye que **al menos una de las variables explicativas** (*HIV/AIDS*, *Income composition of resources* o *Adult Mortality*) tiene un **efecto estad√≠sticamente significativo** sobre la **esperanza de vida**. Esto valida que el modelo general propuesto tiene una capacidad real para explicar el comportamiento de la variable dependiente y que las relaciones observadas entre las variables no son producto del azar.


## Pruebas de significancia individuales 

A diferencia de la prueba global, que eval√∫a el impacto conjunto de todas las variables, en esta secci√≥n analizamos cada variable independiente por separado. Para cada una, comparamos el valor p con el nivel de significancia (ùõº= 0.05 para determinar si rechazamos la hip√≥tesis nula y concluimos que la variable tiene un impacto significativo sobre la **expectativa de vida**.

```{r}
summary_resultado <- summary(modelo)
coeficientes <- summary_resultado$coefficients
alpha <- 0.05

variables <- c("HIV/AIDS", "Income composition of resources", "Adult Mortality")

hipotesis_table <- data.frame(
  Variable = variables,
  `Hip√≥tesis nula` = c("$H_0: \\beta_1 = 0$", "$H_0: \\beta_2 = 0$", "$H_0: \\beta_3 = 0$"),
  `Hip√≥tesis alternativa` = c("$H_1: \\beta_1 \\neq 0$", "$H_1: \\beta_2 \\neq 0$", "$H_1: \\beta_3 \\neq 0$"),
  `Nivel de significancia` = rep("0.05", 3),
  `Valor t` = round(coeficientes[2:4, 3], 3),
  gl = rep(summary_resultado$df[2], 3),
  `Valor p` = format(coeficientes[2:4, 4], scientific = TRUE, digits = 3),
  Comparaci√≥n = ifelse(coeficientes[2:4, 4] < alpha, "Valor p < Œ±", "Valor p > Œ±"),
  Decisi√≥n = ifelse(coeficientes[2:4, 4] < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$")
)

# Cambiar los nombres visibles de las columnas para la tabla
colnames(hipotesis_table) <- c(
  "Variable",
  "Hip√≥tesis nula",
  "Hip√≥tesis alternativa",
  "Nivel de significancia",
  "Valor t",
  "gl",
  "Valor p",
  "Comparaci√≥n",
  "Decisi√≥n"
)

hipotesis_table %>%
  kbl(
    format = "html",
    caption = "Prueba de Hip√≥tesis para las Variables Independientes del Modelo",
    escape = FALSE,
    align = "c",
    row.names = FALSE
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) %>%
  row_spec(0, bold = TRUE, background = "#e0e0e0")

```
   
Los resultados de la prueba de hip√≥tesis para los coeficientes del modelo muestran que todas las variables independientes incluidas en la regresi√≥n ‚ÄîHIV/AIDS, Income composition of resources y Adult Mortality‚Äî tienen un efecto estad√≠sticamente significativo sobre la esperanza de vida, al nivel de significancia del 5%. En los tres casos, los valores p resultan considerablemente menores a 0.05, lo que permite rechazar la hip√≥tesis nula \( H_0: \beta_i = 0 \), confirmando que sus coeficientes son diferentes de cero y, por tanto, influyen en la variable dependiente. Estos hallazgos evidencian que el modelo no solo es estad√≠sticamente v√°lido, sino que est√° conformado por variables que capturan dimensiones estructurales relevantes sobre la expectativa de vida en 2015.

En particular, la variable HIV/AIDS presenta un valor t de -3.996 y un valor p de 0.000231, lo cual indica un efecto negativo significativo sobre la esperanza de vida. Este resultado sugiere que, a mayor prevalencia de VIH/SIDA en la poblaci√≥n, menor es la esperanza de vida en los pa√≠ses analizados, reflejando el impacto de enfermedades infecciosas sobre los indicadores de salud p√∫blica. Por otro lado, la Income composition of resources muestra un valor t de 11.694 y un valor p pr√°cticamente nulo (2.23e-15), siendo la variable m√°s influyente del modelo. Su relaci√≥n positiva indica que un mayor acceso a recursos econ√≥micos y sociales se asocia directamente con mayores niveles de longevidad. Finalmente, la variable Adult Mortality presenta un valor t de -2.926 y un valor p de 0.00533, tambi√©n significativo. Esto confirma que un aumento en las tasas de mortalidad adulta contribuye a una disminuci√≥n de la esperanza de vida, reforzando la idea de que la supervivencia en edades productivas es clave para el desarrollo humano.


## Supuestos del modelo de regresi√≥n lineal {.tabset}

### Linealidad 

Este supuesto establece que la relaci√≥n entre cada variable independiente y la variable dependiente sea lineal, es decir, que ante cambios en cada variable independiente, la variable dependiente tambi√©n cambie. Para la comprobaci√≥n del cumplimiento de este supuesto, se proceder√° a emplear una gr√°fica de valores ajustados vs residuos y pruebas de hip√≥tesis de Pearson para verificar la asociaci√≥n lineal entre cada variable independiente y la pendiente.

#### Gr√°fica de valores ajustados vs residuos

```{r}
plot(modelo$fitted.values, modelo$residuals,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "steelblue")
abline(h = 0, col = "red", lwd = 2, lty = 2)
```

Como se observa, los residuos se distribuyen de forma relativamente aleatoria alrededor de la l√≠nea horizontal en cero, sin formar curvas ni estructuras definidas, lo que indica que la relaci√≥n entre las variables independientes y la esperanza de vida es aproximadamente lineal. No se observa un patr√≥n en forma de U o de campana que sugiera una relaci√≥n no lineal, lo cual respalda que el modelo est√© correctamente especificado en t√©rminos de forma funcional.

#### Prueba de hip√≥tesis de Pearson

Se proceder√° a evaluar la existencia de una relaci√≥n lineal entre cada variable independiente y la esperanza de vida mediante la prueba de correlaci√≥n de Pearson:

**1. Formulaci√≥n de hip√≥tesis**

- **($H_0$):**  \( \rho = 0 \)  
  No existe asociaci√≥n lineal entre la variable independiente y la variable dependiente.

- **($H_1$):** \( \rho \neq 0 \)  
  Existe asociaci√≥n lineal entre la variable independiente y la variable dependiente.


**2. Nivel de significancia**
 
 \( \alpha = 0.05 \)
 
**3. Estad√≠stico de prueba y valor_p**

```{r, echo=FALSE}
# Nivel de significancia
alpha <- 0.05

# Pruebas de correlaci√≥n de Pearson para las tres variables del modelo
cor_test_1 <- cor.test(datos$`HIV/AIDS`, datos$`Life expectancy`, method = "pearson")
cor_test_2 <- cor.test(datos$`Income composition of resources`, datos$`Life expectancy`, method = "pearson")
cor_test_3 <- cor.test(datos$`Adult Mortality`, datos$`Life expectancy`, method = "pearson")

variables <- c("HIV/AIDS", "Income composition of resources", "Adult Mortality")

hipotesis_table_cor <- data.frame(
  variables,
  rep("$H_0: \\rho = 0$", 3),
  rep("$H_1: \\rho \\neq 0$", 3),
  rep("0.05", 3),
  round(c(cor_test_1$statistic, cor_test_2$statistic, cor_test_3$statistic), 3),
  rep(cor_test_1$parameter, 3),
  format(c(cor_test_1$p.value, cor_test_2$p.value, cor_test_3$p.value), scientific = TRUE, digits = 3),
  ifelse(c(cor_test_1$p.value, cor_test_2$p.value, cor_test_3$p.value) < alpha, "Valor p < Œ±", "Valor p > Œ±"),
  ifelse(c(cor_test_1$p.value, cor_test_2$p.value, cor_test_3$p.value) < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$")
)

colnames(hipotesis_table_cor) <- c(
  "Variable",
  "Hip√≥tesis nula",
  "Hip√≥tesis alternativa",
  "Nivel de significancia",
  "Valor t",
  "gl",
  "Valor p",
  "Comparaci√≥n",
  "Decisi√≥n"
)

hipotesis_table_cor %>%
  kbl(
    format = "html",
    caption = "Prueba de Hip√≥tesis para la Correlaci√≥n de Pearson entre cada Variable Independiente y Life Expectancy",
    escape = FALSE,
    align = "c",
    row.names = FALSE
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) %>%
  row_spec(0, bold = TRUE, background = "#e0e0e0")
```

**4. Interpretaci√≥n y conclusi√≥n**

Los resultados de la prueba de correlaci√≥n de Pearson muestran que existe **una asociaci√≥n lineal significativa** entre cada una de las variables independientes analizadas (*HIV/AIDS*, *Income composition of resources* y *Adult Mortality*) y la variable dependiente *Life expectancy*. En todos los casos, los valores $p$ son extremadamente bajos y menores al nivel de significancia establecido de \( \alpha = 0.05 \) por lo que se **rechaza la hip√≥tesis nula** de que no existe correlaci√≥n lineal entre las variables.En consecuencia, se concluye que todas las variables predictoras del modelo tienen una relaci√≥n lineal estad√≠sticamente significativa con la esperanza de vida, lo que justifica su inclusi√≥n en el an√°lisis de regresi√≥n realizado para el a√±o 2015 y refuerza su relevancia como factores explicativos del fen√≥meno.

### Normalidad 

Para validar el modelo de regresi√≥n lineal m√∫ltiple, es necesario comprobar que los residuos se distribuyen de forma aproximadamente normal. Este supuesto garantiza la validez de las inferencias estad√≠sticas, como los intervalos de confianza y las pruebas de hip√≥tesis aplicadas a los coeficientes. Para evaluar esta condici√≥n, se emplear√°n herramientas gr√°ficas como el gr√°fico Q-Q (quantile-quantile plot) y una prueba estad√≠stica formal como lo es Shapiro Wilk, dado que estamos trabajando con una muestra igual a 50 observaciones.

#### Gr√°fico Q-Q Plot

```{r}
qqnorm(resid(modelo), 
       main = "Gr√°fico Q-Q de los Residuos",
       col = "steelblue", 
       pch = 19)
qqline(resid(modelo), 
       col = "red", 
       lwd = 2, 
       lty = 2)
```

En el gr√°fico Q-Q, la mayor√≠a de los puntos se alinean bastante bien con la l√≠nea diagonal, lo que indica que los residuos del modelo siguen una distribuci√≥n aproximadamente normal, especialmente en el rango central de los datos. Esta alineaci√≥n es una buena se√±al, ya que respalda el cumplimiento del supuesto de normalidad en los errores. Sin embargo, se aprecian algunas desviaciones leves en las colas, donde los residuos m√°s extremos se alejan ligeramente de la l√≠nea te√≥rica. Esto podr√≠a deberse a la presencia de valores at√≠picos o a ligeras desviaciones respecto a la normalidad en los extremos. Para complementar esta evaluaci√≥n visual, se aplicar√° la prueba de normalidad de Shapiro-Wilk con el fin de verificar de forma estad√≠stica si los residuos pueden considerarse normalmente distribuidos.

#### Shapiro Wilk

Para verificar el cumplimiento del supuesto de normalidad de los errores del modelo de regresi√≥n, se aplicar√° la prueba de **Shapiro-Wilk**:

**1. Formulaci√≥n de hip√≥tesis**

- Hip√≥tesis nula ($H_0$): Los residuos del modelo siguen una distribuci√≥n normal.

- Hip√≥tesis alternativa ($H_1$): Los residuos del modelo no siguen una distribuci√≥n normal.

**2. Nivel de significancia**
 
 \( \alpha = 0.05 \)
 
**3. Estad√≠stico de prueba y valor_p**

```{r}
residuos <- residuals(modelo)

# Aplicar la prueba de Shapiro-Wilk
shapiro.test(residuos)
```

**4. Comparaci√≥n e interpretaci√≥n**

$$
p = 0.2883 > \alpha = 0.05
$$
El resultado de la prueba arroja un p-valor de 0.2883, el cual es mayor que el nivel de significaci√≥n establecido (Œ± = 0.05). Por tanto, no se rechaza la hip√≥tesis nula (H‚ÇÄ), lo que indica que no hay evidencia suficiente para afirmar que los datos se desv√≠an significativamente del supuesto planteado.

**5. Conclusi√≥n**

Si se establece un **nivel de significancia de \( \alpha = 0.05 \)**, el resultado de la **prueba de normalidad de Shapiro-Wilk** aplicada a los residuos del modelo arroja un estad√≠stico \( W = 0.9724 \) y un **valor p = 0.2883**. Dado que el valor p es **mayor al nivel de significancia**, **no se rechaza la hip√≥tesis nula**, lo que indica que **no hay evidencia estad√≠stica suficiente para afirmar que los residuos se desv√≠an de una distribuci√≥n normal**. Este hallazgo es coherente con el gr√°fico Q-Q, donde los puntos siguen de forma razonable la l√≠nea diagonal. En conjunto, estos resultados sugieren que **el supuesto de normalidad de los errores se cumple**, respaldando la validez del modelo en este aspecto.

### Multicolinealidad 

La multicolinealidad se presenta cuando algunas variables independientes del modelo est√°n fuertemente relacionadas entre s√≠, lo que puede afectar la interpretaci√≥n de los coeficientes y reducir la precisi√≥n de las estimaciones. Para verificar si existe este problema, se analizar√° la matriz de correlaci√≥n entre las variables:

```{r}
variables_indep <- datos[, c("HIV/AIDS", "Income composition of resources", "Adult Mortality")]

correlaciones <- round(cor(variables_indep, use = "complete.obs", method = "pearson"), 3)

correlaciones %>%
  kable("html", caption = "Matriz de Correlaci√≥n entre las Variables", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE, 
                position = "center")
```


La matriz de correlaci√≥n evidencia que no existe una relaci√≥n lineal fuerte entre las variables independientes, ya que todos los coeficientes se encuentran por debajo del umbral de ¬±0.7, lo cual descarta la presencia de multicolinealidad severa. La correlaci√≥n entre *HIV/AIDS* e *Income composition of resources* es de -0.249, indicando una asociaci√≥n d√©bil y negativa. Entre *HIV/AIDS* y *Adult Mortality* se observa una relaci√≥n moderada y positiva con un coeficiente de 0.529, mientras que *Income composition of resources* y *Adult Mortality* presentan una relaci√≥n moderada y negativa de -0.458. Estas asociaciones, aunque presentes, no son lo suficientemente altas como para comprometer la independencia entre los predictores. Por tanto, puede asumirse que cada variable aporta valor √∫nico al modelo y sus efectos pueden interpretarse de manera confiable.

### Autocorrelaci√≥n de los residuos 

En los modelos de regresi√≥n lineal, uno de los supuestos fundamentales es que los residuos sean independientes entre s√≠. La autocorrelaci√≥n ocurre cuando los errores est√°n correlacionados, es decir, cuando el valor de un residuo depende del anterior. Este fen√≥meno puede generar estimaciones ineficientes y valores p poco confiables. Para evaluar este supuesto, se utiliza la prueba de Durbin-Watson:

**1. Formulaci√≥n de hip√≥tesis**

- **Hip√≥tesis nula (\( H_0 \))**: \( \rho = 0 \)  
  No existe autocorrelaci√≥n en los residuos del modelo.

- **Hip√≥tesis alternativa (\( H_1 \))**: \( \rho \neq 0 \)  
  Existe autocorrelaci√≥n en los residuos del modelo.

**2. Nivel de significancia**
 
 \( \alpha = 0.05 \)
 
**3. Estad√≠stico de prueba y valor_p**  

```{r}
library(lmtest)

# Prueba de Durbin-Watson al modelo
dwtest(modelo)
```

**4. Comparaci√≥n e interpretaci√≥n**

$$
p = 0.8361 > \alpha = 0.05
$$
El resultado de la prueba arroja un p-valor de 0.8361, el cual es mayor que el nivel de significaci√≥n establecido (Œ± = 0.05). Por tanto, no se rechaza la hip√≥tesis nula (H‚ÇÄ), lo que indica que no hay evidencia suficiente para afirmar que los datos se desv√≠an significativamente del supuesto planteado.

**5. Conclusi√≥n**

El estad√≠stico **Durbin-Watson** fue **2.2727** con un **valor p = 0.8361**. Como el valor p es mayor que el nivel de significancia \( \alpha = 0.05 \), **no se rechaza la hip√≥tesis nula**, lo que indica que **no hay evidencia de autocorrelaci√≥n positiva** en los residuos. Adem√°s, el valor de DW est√° dentro del rango aceptable (entre 1.5 y 2.5), por lo que se considera que **los errores del modelo son independientes**. Esto es apropiado en este caso, ya que los datos provienen de distintos pa√≠ses en un solo a√±o, y no se espera una relaci√≥n temporal entre las observaciones.


### Homocedasticidad 

En un modelo de regresi√≥n, los errores deber√≠an mantenerse con una dispersi√≥n similar en todos los niveles de los valores ajustados. Si esto no ocurre, se habla de heterocedasticidad, lo que puede afectar la confiabilidad del modelo. Por eso es importante verificar este supuesto con gr√°ficos y pruebas como la de Breusch-Pagan:

#### Gr√°fica de valores ajustados vs residuos**

```{r}
plot(modelo$fitted.values, modelo$residuals,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "steelblue")
abline(h = 0, col = "red", lwd = 2, lty = 2)
```

En el gr√°fico no se observa una forma definida ni un patr√≥n evidente en la dispersi√≥n de los residuos. Los puntos parecen distribuidos de manera irregular alrededor de la l√≠nea cero y la variaci√≥n se mantiene m√°s o menos constante en todo el rango de los valores ajustados, por lo que visualmente se podr√≠a aceptar que el modelo cumple con el supuesto de homocedasticidad.

#### Breusch-Pagan

**1. Formulaci√≥n de hip√≥tesis**

- **Hip√≥tesis nula (\( H_0 \))**: Hay homocedasticidad  
La varianza de los residuos del modelo es constante.

- **Hip√≥tesis alternativa (\( H_1 \))**: Hay heterocedasticidad  
La varianza de los residuos del modelo no es constante.

**2. Nivel de significancia**
 
 \( \alpha = 0.05 \)
 
**3. Estad√≠stico de prueba y valor_p**  

```{r}
library(lmtest)

# Test de Breusch-Pagan
bptest(modelo)
```
**4. Comparaci√≥n e interpretaci√≥n**

$$
p = 0.8361 > \alpha = 0.05
$$

El resultado de la prueba arroja un p-valor de 0.8361, el cual es mayor que el nivel de significaci√≥n establecido (Œ± = 0.05). Por tanto, no se rechaza la hip√≥tesis nula (H‚ÇÄ), lo que indica que no hay evidencia suficiente para afirmar que los datos se desv√≠an significativamente del supuesto planteado.

**5. Conclusi√≥n**

Al aplicar la prueba de Breusch-Pagan para evaluar la homocedasticidad de los residuos del modelo, se obtuvo un estad√≠stico \( BP = 5.0066 \) con 3 grados de libertad y un valor p de 0.1713.Al tener un nivel de significancia de \( \alpha = 0.05 \), este valor p es mayor al umbral, por lo tanto, no se rechaza la hip√≥tesis nula de homocedasticidad. Esto indica que no hay evidencia estad√≠stica suficiente para afirmar que la varianza de los residuos no es constante, lo cual sugiere que el supuesto de homocedasticidad se cumple en el modelo, aportando mayor confianza en la validez de las inferencias realizadas.


# Bibliograf√≠a
